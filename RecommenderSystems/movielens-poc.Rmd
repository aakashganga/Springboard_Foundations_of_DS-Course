---
title: "Building a Movie Recommendation System using R- Recommenderlab package"
author: "Vijay Raghunath, mentored by Amit Dingare"
date: "November, 2016"
output: html_notebook
---

## Project Overview

In this project, we develop a recommender system for recommending movies for the MovieLens database.

Initially the recommender system will be build using the colloborative filtering recommender (CFR) algorithm.

The basic idea of CFR systems is that, if two users share the same interests in the past, e.g. they liked the same book or the same movie, they will also have similar tastes in the future. If, for example, user A and user B have a similar purchase history and user A recently bought a book that user B has not yet seen, the basic idea is to propose this book to user B.

The collaborative filtering approach considers only user preferences and does not take into account the features or contents of the items (books or movies) being recommended.

## Used Libraries

The following libraries were used in this project:

```{r libs, warning=FALSE, error=FALSE, message=FALSE}
library(recommenderlab)
library(ggplot2)
library(tidyr)
library(data.table)
```

## UML class diagram for package recommenderlab
image: ![](recommenderlab-UML.png)

By using the algorithms available in Recommenderlab package, we can achieve 2-fold purpose:

* Predict the ratings for the movies that the user has not seen
* After having predicted all the ratings for the user, we can make a top-N recommendation for the users. This top-N recommendation list can be further drilled down for the genre preferred by the user.

### Recommenderlab Infrastructure
The package uses the abstract ratingMatrix to provide a common interface for rating data.
ratingMatrix implements many methods typically available for matrix-like objects.
For example, dim(), dimnames(), colCounts(), rowCounts(), colMeans(), rowMeans(), colSums()
and rowSums(). Additionally sample() can be used to sample from users (rows) and image()
produces an image plot.

For ratingMatrix we provide two concrete implementations realRatingMatrix and
binaryRatingMatrix to represent different types of rating matrices.
 
* realRatingMatrix - Implements a rating matrix with real valued ratings stored in sparse format defined in package Matrix. Sparse matrices in Matrix typically do not store 0s explicitly, however for realRatingMatrix we use these sparse matrices such that instead of 0s, NAs are not explicitly stored.

* binaryRatingMatrix - implements a 0-1 rating matrix using the implementation of itemMatrix
defined in package arules. itemMatrix stores only the ones and internally uses a sparse rep-
resentation from package Matrix. With this class structure recommenderlab can be easily
extended to other forms of rating matrices with different concepts for efficient storage in the
future.

### Exploring Parameters of Recommendation Models
```{r}
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommender_models)
lapply(recommender_models, "[[", "description")
```



## Dataset

The datasets for this project can be downloaded from the following site:
http://grouplens.org/datasets/movielens/latest.

There are two sets of data having different number of observations â€“

1. Small dataset - It contains 105339 ratings and 6138 tag applications across 10329 movies. These data were created by 668 users between April 03, 1996 and January 09, 2016. 

2. Large dataset- It contains 22884377 ratings and 586994 tag applications across 34208 movies. These data were created by 247753 users between January 09, 1995 and January 29, 2016.

For initial model building and validation, the smaller dataset is used.

The data are contained in four files: links.csv, movies.csv, ratings.csv and tags.csv. 

A brief description of the data files is as below - 

File Name | File Description
------------- | -------------
ratings.csv | All ratings are contained in the file `ratings.csv`. Each line of this file after                  the header row represents one rating of one movie by one user, and has the                       following format: `userId, movieId, rating, timestamp`.
movies.csv | Movie information is contained in the file `movies.csv`. Each line of this file                 after the header row represents one movie, and has the following format:                         `movieId, title, genres`. Movie titles are entered manually or imported from                     <https://www.themoviedb.org/>, and include the year of release in parentheses.Errors             and inconsistencies may exist in these titles.
links.csv | Identifiers that can be used to link to other sources of movie data are contained in             the file `links.csv`. Each line of this file after the header row represents one                 movie, and has the following format: `movieId, imdbId, tmdbId`.
tags.csv | All tags are contained in the file `tags.csv`. Each line of this file after the header             row represents one tag applied to one movie by one user, and has the following                   format: `userId, movieId, tag, timestamp`.

We only use the files movies.csv and ratings.csv to build a recommendation system. These files are used to build the user item ratings matrix, needed by the colloborative algorithms that are available with the *Recommenderlab* package.

```{r data_load, warning=FALSE, error=FALSE, echo=FALSE}
movies <- read.csv("data/movies.csv",stringsAsFactors=FALSE)
ratings <- read.csv("data/ratings.csv")
```

A summary of *movies* is given below, together with several first rows of a dataframe:
```{r mov_summ, warning=FALSE, error=FALSE, message=FALSE}
summary(movies)
head(movies)
```

And here is a summary and a head of *ratings*:
```{r rat_summ, warning=FALSE, error=FALSE, message=FALSE}
summary(ratings)
head(ratings)
```

## Data Pre-processing

### Extract a list of genres
Using __one-hot encoding__ to create a matrix of corresponding genres for each movie. This will help us to generate the list of recommendations for movies based on genres preferred by the user.
Even if we do not use the matrix to give genre based recommendation, we will be needing it to find similarities between users for the rating matrix.
```{r}
genres <- as.data.frame(movies$genres, stringsAsFactors=FALSE)

genres2 <- as.data.frame(tstrsplit(genres[,1], '[|]', 
                                   type.convert=TRUE), 
                         stringsAsFactors=FALSE)
colnames(genres2) <- c(1:10)

genre_list <- c("Action", "Adventure", "Animation", "Children", 
                "Comedy", "Crime","Documentary", "Drama", "Fantasy",
                "Film-Noir", "Horror", "Musical", "Mystery","Romance",
                "Sci-Fi", "Thriller", "War", "Western") # we have 18 genres in total

genre_matrix <- matrix(0,10330,18) #empty matrix, 10330=no of movies+1, 18=no of genres
genre_matrix[1,] <- genre_list #set first row to genre list
colnames(genre_matrix) <- genre_list #set column names to genre list

#iterate through matrix
for (i in 1:nrow(genres2)) {
  for (c in 1:ncol(genres2)) {
    genmat_col = which(genre_matrix[1,] == genres2[i,c])
    genre_matrix[i+1,genmat_col] <- 1
  }
}

 #remove first row, which was the genre list
genre_matrix2 <- as.data.frame(genre_matrix[-1,], stringsAsFactors=FALSE)
for (c in 1:ncol(genre_matrix2)) {
  genre_matrix2[,c] <- as.integer(genre_matrix2[,c])  #convert from characters to integers
} 

```
```{r rat_genre_matric, warning=FALSE, error=FALSE, message=FALSE}
summary(genre_matrix2)
head(genre_matrix2)
```


```{r search_genres, warning=FALSE, error=FALSE, echo=FALSE}
search_matrix <- cbind(movies[,1:2], genre_matrix2)
head(search_matrix)
```
It is seen from the ratings matrix above that each movie can correspond to one or more genres.

### Converting ratings matrix in a proper format

In order to use the ratings data for building a recommendation engine with *recommenderlab*, convert rating matrix into a sparse matrix of type *realRatingMatrix*.

```{r rat_mat, warning=FALSE, error=FALSE, echo=FALSE}
ratingmat <- dcast(ratings, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingmat <- as.matrix(ratingmat[,-1]) #remove userIds

#Convert rating matrix into a recommenderlab sparse matrix
ratingmat <- as(ratingmat, "realRatingMatrix")
```
668 x 10325 rating matrix of class 'realRatingMatrix' with 105339 ratings.
<!-- ### Synchronize dimensions of matrices (???) -->

<!-- ```{r mat_dims, warning=FALSE, error=FALSE} -->
<!-- #Remove rows that are not rated from movies dataset -->
<!-- movieIds <- length(unique(movies$movieId)) #10329 -->
<!-- ratingmovieIds <- length(unique(ratings$movieId)) #10325 -->
<!-- movies2 <- movies[-which((movies$movieId %in% ratings$movieId) == FALSE),] -->
<!-- rownames(movies2) <- NULL -->

<!-- #Remove rows that are not rated from genre_matrix2 -->
<!-- genre_matrix3 <- genre_matrix2[-which((movies$movieId %in% ratings$movieId) == FALSE),] -->
<!-- rownames(genre_matrix3) <- NULL -->
<!-- ``` -->

## Explore values of movies ratings
```{r rate_values, warning=FALSE, error=FALSE}
vector_ratings <- as.vector(ratingmat@data)
unique(vector_ratings) # what are unique values of ratings

table_ratings <- table(vector_ratings) # what is the count of each rating value
table_ratings
```
There are 11 unique score values. The lower values mean lower ratings and vice versa.

### Distribution of the ratings

According to the documentation, a rating equal to 0 represents a missing value, hence it is removed from the dataset before visualizing the results.
```{r}
 # rating == 0 are NA values
vector_ratings <- vector_ratings[vector_ratings != 0]
vector_ratings <- factor(vector_ratings)

qplot(vector_ratings) + ggtitle("Distribution of the ratings")
```
There are less low (less than 3) rating scores, the majority of movies are rated with a score of 3 or higher. The most common rating is 4.

### Number of views of the top movies
```{r  top_no, warning=FALSE, error=FALSE, echo=FALSE}
views_per_movie <- colCounts(ratingmat) # count views for each movie

table_views <- data.frame(movie = names(views_per_movie),
                          views = views_per_movie) # create dataframe of views
table_views <- table_views[order(table_views$views, 
                                 decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
for (i in 1:10325){
  table_views[i,3] <- as.character(subset(movies, 
                                         movies$movieId == table_views[i,1])$title)
}

table_views[1:6,]

ggplot(table_views[1:6, ], aes(x = title, y = views)) +
  geom_bar(stat="identity") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
ggtitle("Number of views of the top movies")

```
From the plot, it can be seen that "Pulp Fiction (1994)" is the most viewed movie, exceeding the second-most-viewed "Forrest Gump (1994)" by 14 views.

### Distribution of the average movie rating
```{r avg_rat, warning=FALSE, error=FALSE, echo=FALSE, message=FALSE}
average_ratings <- colMeans(ratingmat)

qplot(average_ratings) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Distribution of the average movie rating")
```
The distribution above shows the distribution of the average movie rating. The highest value is around 3, and there are a few movies whose rating is either 1 or 5. Probably, the reason is that these movies received a rating from a few people only, so shouldn't take them into account.

Assigning a threshold value of minimum of 50 views per user, create a subset of only relevant movies. 
```{r}
average_ratings_relevant <- average_ratings[views_per_movie > 50] 
qplot(average_ratings_relevant) + 
  stat_bin(binwidth = 0.1) +
  ggtitle(paste("Distribution of the relevant average ratings"))
```

The second image above shows the distribution of the relevant average ratings. All the rankings are between 2.16 and 4.45. As expected, the extremes were removed. The highest value changes, and now it is around 4.


### Heatmap of the rating matrix
Visualizing the whole matrix of ratings by building a heat map whose colors represent the ratings. Each row of the matrix corresponds to a user, each column to a movie, and each cell to its rating.
```{r heat_rate, warning=FALSE, error=FALSE, echo=FALSE}
image(ratingmat, main = "Heatmap of the rating matrix")

```

Since there are too many users and items, the heatmap chart is hard to read hard as it has too many dimensions.

```{r}
image(ratingmat[1:20, 1:25], main = "Heatmap of the first 20 rows and 25 columns")
```
Zooming in on the first rows and columns, it can be observed that the some users saw more movies than the others.

To avoid this user bias, an efficient recommendation algorithm should select the most relevant users (the users who have seen many movies) and movies (the movies that have been seen by many users). To select the most relevant users and movies, the following steps are followed -

1. Determine the minimum number of movies per user.
2. Determine the minimum number of users per movie.
3. Select the users and movies matching these criteria.

```{r heat_relev, warning=FALSE, error=FALSE, echo=FALSE}
min_n_movies <- quantile(rowCounts(ratingmat), 0.99)
min_n_users <- quantile(colCounts(ratingmat), 0.99)
print("Minimum number of movies per user:")
min_n_movies
print("Minimum number of users per movie:")
min_n_users

image(ratingmat[rowCounts(ratingmat) > min_n_movies,
                 colCounts(ratingmat) > min_n_users], 
main = "Heatmap of the top users and movies")
```
From above heatmap the following points can be observed - 

* Of the users having watched more movies, most of them have seen all the top movies.
* Some columns of the heatmap are darker than the others, meaning that these columns represent the highest-rated movies.
* Conversely, darker rows represent users giving higher ratings.

Because of the above factors, it would be a good to normalize the data before building the model.

## Data Preparation

The data preparation process consists of the following steps:

1. Select the relevant data.
2. Normalize the data.
3. Binarize the data.

## Select the relevant data - 

In order to select the most relevant data, the minimum number of users per rated movie is defined as 50 and the minimum views number per movie as 50:

```{r rel_data, warning=FALSE, error=FALSE, echo=FALSE}
ratings_movies <- ratingmat[rowCounts(ratingmat) > 50,
                             colCounts(ratingmat) > 50]
```
420 x 447 rating matrix of class â€˜realRatingMatrixâ€™ with 38341 ratings.


Such a selection of the most relevant data contains 420 users and 447 movies, compared to previous 668 users and 10325 movies in the total dataset.

Using the same approach as previously, visualize the top 2 percent of users and movies in the new matrix of the most relevant data:

```{r}
min_movies <- quantile(rowCounts(ratings_movies), 0.98)
min_users <- quantile(colCounts(ratings_movies), 0.98)
image(ratings_movies[rowCounts(ratings_movies) > min_movies,
                     colCounts(ratings_movies) > min_users], 
main = "Heatmap of the top users and movies")

average_ratings_per_user <- rowMeans(ratings_movies)
qplot(average_ratings_per_user) + stat_bin(binwidth = 0.1) +
  ggtitle("Distribution of the average rating per user")
```

In the heatmap, some rows are darker than the others. This might mean that some users give higher ratings to all the movies. The distribution of the average rating per user across all the users varies a lot, as the second chart above shows.
    
## Normalizing the data -

Having users who give high (or low) ratings to all their movies might bias the results. In order to remove this effect, we normalize the data in such a way that the average rating of each user is 0.
```{r}
ratings_movies_norm <- normalize(ratings_movies)
sum(rowMeans(ratings_movies_norm) > 0.00001)
```

Visualizing the normalized matrix for the top movies. It is colored now because the data is continuous:
```{r viz_normal_data, warning=FALSE, error=FALSE, echo=FALSE}
image(ratings_movies_norm[rowCounts(ratings_movies_norm) > min_movies,
                          colCounts(ratings_movies_norm) > min_users], 
main = "Heatmap of the top users and movies")
```


There are still some lines that seem to be more blue or more red. The reason
is that I am visualizing only the top movies. We have already checked that the average rating is 0 for each user, so there is no bias in the user ratings.

## Binarizing the data
Some recommendation models work on binary data, so it might be useful to binarize the data, that is, define a table containing only 0s and 1s. The 0s will be either treated as missing values or as bad ratings.

We can either:

* Define a matrix having 1 if the user rated the movie, and 0 otherwise. In this case, the information about the rating is lost.

* Define a matrix having 1 if the rating is above or equal to a definite threshold (for example, 3), and 0 otherwise. In this case, giving a bad rating to a movie is equivalent to not having rated it.

Depending on the context, one choice may be more appropriate than the other.

As a next step, two matrices following the two different approaches are defined. Visualize a 5 percent portion of each of binarized matrices.

#### 1st option: define a matrix equal to 1 if the movie has been watched

```{r binar_data1, warning=FALSE, error=FALSE, echo=FALSE}
ratings_movies_watched <- binarize(ratings_movies, minRating = 1)
min_movies_binary <- quantile(rowCounts(ratings_movies), 0.95)
min_users_binary <- quantile(colCounts(ratings_movies), 0.95)
image(ratings_movies_watched[rowCounts(ratings_movies) > min_movies_binary,
                             colCounts(ratings_movies) > min_users_binary], 
main = "Heatmap of the top users and movies")
```

#### 2nd option: define a matrix equal to 1 if the cell has a rating above the threshold

```{r binar_data2, warning=FALSE, error=FALSE, echo=FALSE}
ratings_movies_good <- binarize(ratings_movies, minRating = 3)
image(ratings_movies_good[rowCounts(ratings_movies) > min_movies_binary, 
colCounts(ratings_movies) > min_users_binary], 
main = "Heatmap of the top users and movies")
```

There are more white cells in the second heatmap, which shows that there are more movies with no or bad ratings than those that were not watched by raters.

## ITEM-based Collaborative Filtering Model

Collaborative filtering is a branch of recommendation that takes account of the information about different users. The word "collaborative" refers to the fact that users collaborate with each other to recommend items. In fact, the algorithms take account of user ratings and preferences.

The starting point is a rating matrix in which rows correspond to users and columns correspond to items. The core algorithm is based on these steps:

1. For each two items, measure how similar they are in terms of having received similar ratings by similar users
2. For each item, identify the k most similar items
3. For each user, identify the items that are most similar to the user's purchases

## Defining training/test sets

We build the model using 80% of the whole dataset as a training set, and 20% - as a test set.

```{r train_test_sets, warning=FALSE, message=FALSE, echo=FALSE}
which_train <- sample(x = c(TRUE, FALSE), 
                      size = nrow(ratings_movies),
                      replace = TRUE, 
                      prob = c(0.8, 0.2))
#head(which_train)

recc_data_train <- ratings_movies[which_train, ]
recc_data_test <- ratings_movies[!which_train, ]

# which_set <- sample(x = 1:5, 
#                     size = nrow(ratings_movies), 
#                     replace = TRUE)
# for(i_model in 1:5) {
#   which_train <- which_set == i_model
#   recc_data_train <- ratings_movies[which_train, ]
#   recc_data_test <- ratings_movies[!which_train, ]
# }
```
## Building the recommendation model

A look at the default parameters of IBCF model. 

Here, *k* is the number of items to compute the similarities among them in the first step. After, for each item, the algorithm identifies its *k* most similar items and stores the number. *method* is a similarity function, which is *Cosine* by default, may also be *Pearson*. The recommender model is developed using the default parameters of method = Cosine and k=30.

```{r build_recommenderIBCF, warning=FALSE, message=FALSE, echo=FALSE}
recommender_models <- recommenderRegistry$get_entries(dataType ="realRatingMatrix")
recommender_models$IBCF_realRatingMatrix$parameters

recc_model <- Recommender(data = recc_data_train, 
                          method = "IBCF",
                          parameter = list(k = 30))

recc_model
class(recc_model)
```

Exploring the recommender model:

```{r explore_IBCF, warning=FALSE, message=FALSE, echo=FALSE}
model_details <- getModel(recc_model)
#model_details$description
#model_details$k

class(model_details$sim) # this contains a similarity matrix
dim(model_details$sim)

n_items_top <- 20
image(model_details$sim[1:n_items_top, 1:n_items_top],
      main = "Heatmap of the first rows and columns")

row_sums <- rowSums(model_details$sim > 0)
table(row_sums)
col_sums <- colSums(model_details$sim > 0)
qplot(col_sums) + stat_bin(binwidth = 1) + ggtitle("Distribution of the column count")
```

*dgCMatrix* is a similarity matrix created by the model. Its dimensions are 447 x 447, which is equal to the number of items. The heatmap of 20 first items show that many values are equal to 0. The reason is that each row contains only k (30) elements that are greater than 0. The number of non-null elements for each column depends on how many times the corresponding movie was included in the top k of another movie. Thus, the matrix is not neccessarily simmetric, which is also the case in our model. 

The chart of the distribution of the number of elements by column shows there are a few movies that are similar to many others. 

## Applying recommender system on the dataset:

Now, it is possible to recommend movies to the users in the test set. I define
*n_recommended* equal to 10 that specifies the number of movies to recommend to each user.

For each user, the algorithm extracts its rated movies. For each movie, it identifies all its similar items, starting from the similarity matrix. Then, the algorithm ranks each similar item in this way:

* Extract the user rating of each purchase associated with this item. The rating is used as a weight.
* Extract the similarity of the item with each purchase associated with this item.
* Multiply each weight with the related similarity. 
* Sum everything up.

Then, the algorithm identifies the top 10 recommendations:

```{r apply_IBCF, warning=FALSE, message=FALSE, echo=FALSE}
n_recommended <- 10 # the number of items to recommend to each user

recc_predicted <- predict(object = recc_model, 
                          newdata = recc_data_test, 
                          n = n_recommended)
##recc_predicted
```

Let's explore the results of the recommendations for the first user:

```{r explore_res_IBCF, warning=FALSE, message=FALSE, echo=FALSE}
#class(recc_predicted)
#slotNames(recc_predicted)

recc_user_1 <- recc_predicted@items[[1]] # recommendation for the first user
movies_user_1 <- recc_predicted@itemLabels[recc_user_1]
movies_user_2 <- movies_user_1
for (i in 1:10){
  movies_user_2[i] <- as.character(subset(movies, 
                                         movies$movieId == movies_user_1[i])$title)
}
movies_user_2
```

It's also possible to define a matrix with the recommendations for each user. 
Below we visualize the recommendations for the first four users:

```{r recc_matrix, warning=FALSE, message=FALSE, echo=FALSE}
recc_matrix <- sapply(recc_predicted@items, 
                      function(x){ as.integer(colnames(ratings_movies)[x]) }) # matrix with the recommendations for each user
#dim(recc_matrix)
recc_matrix[,1:4]
```

Here, the columns represent the first 4 users, and the rows are the *movieId* values of recommended 10 movies.

Now, let's identify the most recommended movies. The following image shows the distribution of the number of items for IBCF:

```{r most_recom_moviesIBCF, warning=FALSE, message=FALSE, echo=FALSE}
number_of_items <- factor(table(recc_matrix))

chart_title <- "Distribution of the number of items for IBCF"
qplot(number_of_items) + ggtitle(chart_title)

number_of_items_sorted <- sort(number_of_items, decreasing = TRUE)
number_of_items_top <- head(number_of_items_sorted, n = 4)
table_top <- data.frame(as.integer(names(number_of_items_top)),
                       number_of_items_top)

for (i in 1:4){
  table_top[i,1] <- as.character(subset(movies, 
                                         movies$movieId == table_top[i,1])$title)
}

colnames(table_top) <- c("Movie title", "No of items")
head(table_top)
```

Most of the movies have been recommended only a few times, and a few movies have been recommended more than 5 times.

IBCF recommends items on the basis of the similarity matrix. It's an eager-learning model, that is, once it's built, it doesn't need to access the initial data. For each item, the model stores the k-most similar, so the amount of information is small once the model is built. This is an advantage in the presence of lots of data.

In addition, this algorithm is efficient and scalable, so it works well with big rating matrices.
